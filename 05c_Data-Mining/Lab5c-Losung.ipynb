{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9d21a7",
   "metadata": {},
   "source": [
    "<h1><center> 5c. Übung: Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e993af0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><h4> Aufgabe 1: Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd85ce",
   "metadata": {},
   "source": [
    "Sie finden den Datensatz *hmeq_modeling* als csv-Datei im Git-Repo oder unter [www.creditriskanalytics.net](http://www.creditriskanalytics.net/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a45708",
   "metadata": {},
   "source": [
    "Der Datensatz enthält Informationen zu den folgenden 13 Variablen:\n",
    "- **BAD**: 1=Kreditausfall; 0=kein Kreditausfall\n",
    "- **LOAN**: Höhe des Kreditantrags\n",
    "- **MORTDUE**: fälliger Betrag für bestehende Hypotheken\n",
    "- **VALUE**: Wert des aktuellen Eigentums\n",
    "- **REASON**: DebtCon=Schuldenkonsolidierung; HomeImp=home improvement\n",
    "- **JOB**: berufliche Kategorien\n",
    "- **YOJ**: Jahre in der gegenwärtigen Beschäftigung\n",
    "- **DEROG**: Anzahl negativer Meldungen\n",
    "- **DELINQ**: Anzahl der in Verzug geratenen Kreditraten\n",
    "- **CLAGE**: Alter des ältesten Kreditrahmens in Monaten\n",
    "- **NINQ**: Anzahl der jüngsten Kreditanfragen\n",
    "- **CLNO**: Anzahl der Kreditraten\n",
    "- **DEBTINC**: Schulden-Einkommen-Verhältnis\n",
    "\n",
    "Die Modellierungsaufgabe besteht darin, den Status der Zielvariable BAD auf Grundlage der restlichen Variaben zu prognostizieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616bf35",
   "metadata": {},
   "source": [
    "a) Laden Sie den Datensatz *hmeq_modeling* als Dataframe. Machen Sie sich einen Überblick über den Datensatz und zeigen Sie, dass keine fehlenden Werte enthalten sind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0557e69",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">Im Datensatz sind nominale Variablen <strong>one-hot kodiert</strong>. Haben wir beispielsweise die Variable \"farben\" mit den Ausprägungen blau, rot und grün, erstellen wir stattdessen drei binäre Variablen \"blau\", \"rot\" und \"grün\". Die drei Variablen haben die Ausprägung 1, wenn die Farbe zutrifft und 0 wenn nicht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\_Daten\\hmeq_modeling.csv\", index_col='ID')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.any(df.isna())==False:\n",
    "    print(\"I confirm the data does not include missing values\")\n",
    "else:\n",
    "    print(\"Actually, the data does include missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151f128",
   "metadata": {},
   "source": [
    "b) Unterteilen Sie den Datensatz zufällig in einen Training- (70 %) und in einen Testdatensatz (30%).\\\n",
    "**Hinweis**: Die Targetvariable in dem Datensatz ist das Merkmal **BAD**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd8d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.pop(\"BAD\")\n",
    "X = df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae96b7",
   "metadata": {},
   "source": [
    "c) Stellen Sie sicher, dass das Verhältnis von 0 und 1 im Trainings- und Testdatensatz *fast identisch* zum Originaldatensatz ist.\\\n",
    "**Hinweis**: Sehen Sie sich hierfür das Argument *stratify* an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_ratio(y):\n",
    "    return np.sum(y)/y.shape[0]\n",
    "\n",
    "print(\"Class ratio in original data: \", class_ratio(y))\n",
    "print(\"Class ratio in training data: \", class_ratio(y_train))\n",
    "print(\"Class ratio in test data: \", class_ratio(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument stratify um sicherzustellen, dass die class distribution im Trainings-/Testdatensatz \n",
    "# so ähnlich wie möglich zu der class ratio im originaldatensatz ist\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "print(\"Class ratio in original data: \", class_ratio(y))\n",
    "print(\"Class ratio in training data: \", class_ratio(y_train))\n",
    "print(\"Class ratio in test data: \", class_ratio(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06780eae",
   "metadata": {},
   "source": [
    "d) Verwenden Sie die **sklearn** Bibliothek um eine logistische Regression, einen Decision Tree (default-Einstellungen, random_state=1234) und einen Random Forest (default-Einstellungen, random_state=1234) zu schätzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22582f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b070bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "learners = [LogisticRegression(penalty='none'), DecisionTreeClassifier(random_state=1234),\n",
    "           RandomForestClassifier(random_state=1234)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03707793",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in learners:\n",
    "    l.fit(X_train, y_train)\n",
    "# FutureWarning ignorieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77edcb4",
   "metadata": {},
   "source": [
    "e) Bewerten Sie die Klassifikatoren auf Grundlage des Testdatensatzes mit Hilfe der ROC-Analyse. Erstellen Sie ein ROC-Diagramm, dass die Performance der drei Klassifikatoren darstellt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c86da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for l in learners:\n",
    "    RocCurveDisplay.from_estimator(l, X_test, y_test, ax=ax)\n",
    "\n",
    "ax.set_title('ROC curve of candidate classifiers')\n",
    "ax.plot([0, 1], [0, 1], \"r--\", label='baseline');  # the random benchmark we need to add manually\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa3586",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><h4> Aufgabe 2: Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a52832",
   "metadata": {},
   "source": [
    "In dieser Aufgabe spezifizieren und trainieren wir ein Neuronales Netz für den HMEQ Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a025e7",
   "metadata": {},
   "source": [
    "a) Instanziieren Sie das sequenzielle Neuronales Netz **nn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b98ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e30289",
   "metadata": {},
   "source": [
    "b) Legen Sie nun die Netzwerkarchitektur fest, in dem Sie nacheinander die Layer hinzufügen:\n",
    "* Ein Dense Layer mit 10 Knoten und einer tanH Aktivierungsfunktion (Denken Sie an `input_shape`)\n",
    "* Ein Dense Layer mit 5 Knoten und einer RELU Aktivierungsfunktion\n",
    "* Ein Output Layer (Dense Layer) mit einem Knoten und einer sigmoid Aktivierungsfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c465b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.add(layers.Dense(units=10, activation='tanh', input_shape=(X_train.shape[1],)))\n",
    "nn.add(layers.Dense(units=5, activation='relu'))\n",
    "nn.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d78a7c",
   "metadata": {},
   "source": [
    "c) Geben Sie die *summary* des Modells aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401cbe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e070473",
   "metadata": {},
   "source": [
    "d) Verwenden Sie `keras.optimizers.SGD` als Optimizer mit einer Lernrate von 0.01 und weisen Sie das dem Objekt `opt` zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a902adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632a4e6b",
   "metadata": {},
   "source": [
    "e) Kompilieren Sie Ihr Modell (`nn.compile()`). Verwenden Sie hierfür den in Aufgabe e) instanziierten Optimizers, eine binary crossentropy und als Metrik die Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a319598",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed8246",
   "metadata": {},
   "source": [
    "f) Trainieren Sie nun Ihr Modell mit Ihrem in Aufgabe 1 erstellten Testdatensatz. Dabei soll die Anzahl an Epochen gleich 10 und der validation_split gleich 0.2 sein.\n",
    "\n",
    "**Achtung**: Aktuell ist unser Datensatz als pandas Dataframe gespeichert. Bevor Sie die Teilaufgabe lösen, müssen Sie zunächst den Trainings- und Testdatensatz als numpy array mit dem Datentyp float abspeichern.<br>\n",
    "Die Target-Variable muss ebenfalls als numpy array vorliegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.asarray(X_train).astype(np.float32), np.asarray(y_train)\n",
    "X_test, y_test = np.asarray(X_test).astype(np.float32), np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30fa47",
   "metadata": {},
   "source": [
    "g) Was gibt Ihnen der nachfolgende Python-Code aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = nn.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbf85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(nn.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf653da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d7e87",
   "metadata": {},
   "source": [
    "h) Lassen Sie sich mithilfe der in der Vorlesung definierten Funktion `show_history()` die Modellperformance ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_history(story):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    ax1.plot(story.history['accuracy'])\n",
    "    ax1.plot(story.history['val_accuracy'])\n",
    "    ax1.set(xlabel='epoch', ylabel='accuracy')\n",
    "    ax1.legend(['train_accuracy', 'test_accuracy'], loc='best')\n",
    "    ax1.set_title('Accuracy evolution during NN training')\n",
    "    \n",
    "    ax2.plot(story.history['loss'])\n",
    "    ax2.plot(story.history['val_loss'])\n",
    "    ax2.set(xlabel='epoch', ylabel='loss')\n",
    "    ax2.legend(['train_loss', 'test_loss'], loc='best')\n",
    "    ax2.set_title('Loss evolution during NN training')\n",
    "    plt.show()\n",
    "\n",
    "show_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
